{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About dataset\n",
    "### Kaggle Competition | Titanic Machine Learning from Disaster\n",
    "\n",
    ">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.  This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    ">One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.  Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    ">In this contest, we ask you to complete the analysis of what sorts of people were likely to survive.  In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    ">This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n",
    "\n",
    "From the competition [homepage](http://www.kaggle.com/c/titanic-gettingStarted).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target = \"_blank\" href = \"https://colab.research.google.com/github/PrzemekSekula/DeepLearningClasses1/blob/master/Titanic/Titanic_empty.ipynb\" >\n",
    "<img src = \"https://www.tensorflow.org/images/colab_logo_32px.png\" / >\n",
    "Run in Google Colab </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you are using Google Colab\n",
    "#!wget https://raw.githubusercontent.com/PrzemekSekula/DeepLearningClasses1/master/Titanic/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataframe\n",
    "Let's read our data in using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "The files we read in the previous screen are available on the data page for the Titanic competition on Kaggle. That page also has a data dictionary, which explains the various columns that make up the data set. Below are the descriptions contained in that data dictionary:\n",
    "\n",
    "- PassengerID - A column added by Kaggle to identify each row and make submissions easier\n",
    "- Survived - Whether the passenger survived or not and the value we are predicting (0=No, 1=Yes)\n",
    "- Pclass - The class of the ticket the passenger purchased (1=1st, 2=2nd, 3=3rd)\n",
    "- Sex - The passenger's sex\n",
    "- Age - The passenger's age in years\n",
    "- SibSp - The number of siblings or spouses the passenger had aboard the Titanic\n",
    "- Parch - The number of parents or children the passenger had aboard the Titanic\n",
    "- Ticket - The passenger's ticket number\n",
    "- Fare - The fare the passenger paid\n",
    "- Cabin - The passenger's cabin number\n",
    "- Embarked - The port where the passenger embarked (C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the missing values for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take care of missing values:\n",
    "The features `cabin` has many missing values and so canâ€™t add much value to our analysis. To handle this we will drop them from the dataframe to preserve the integrity of our dataset. It is also a good idea do delete the name of the passanger and the number of ticket - this data also cannot probably improve the quality of our predictions. Let's do it with pandas.\n",
    "\n",
    "    df = df.drop(['ticket','cabin', 'Name'], axis=1) \n",
    "\n",
    "The next step is to do something with other missing values. Please note that we have 2 missing values in `Embarked` and 177 in `Age` columns. There are several possible solutions, one of them is simply delete all the rows with missing values. You can do it using the following pandas function.\n",
    "   \n",
    "    df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 -  Let's take a look at our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 a) Data analysis\n",
    "Let's check:\n",
    "- how many people survived, and how many don't *(hint - google for pandas value_counts)*\n",
    "- what is the Passanger Class (`Pclass` column) distribution of our data\n",
    "- what is the age distribution of our data *(hint - use pandas histogram)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b -  Correlation analysis \n",
    "Prepare the correlation analysis of the data. In analysis you should display the information about correlations between each pair of variables.\n",
    "\n",
    "*Hint: You may google for `pandas correlation matrix heatmap` to find the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Select features and labels\n",
    "Create the new dataframes/series:\n",
    "- `X` - with the features\n",
    "- `y` - with the labels\n",
    "\n",
    "These dataframes should be ready to use train_test_split, and then to perform machine learning.\n",
    "\n",
    "**Note: This task will be probably done iteratively - you may get back to this task every time you want to improve your results **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 One-hot Encoding\n",
    "Perform one-hot encoding if necessary. \n",
    "\n",
    "*Hint: Use `pd.get_dummies`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Train test split\n",
    "<img src=\"./images/TrainTestSplit.jpg\">\n",
    "Split the data into training and testing sets. Use the following parameters:\n",
    "- Size of testing set = 25% of entire datasize\n",
    "- Your training / testing sets should contain aproximately the same ratio of survived (use `stratify`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Train your model\n",
    "Create and train your model. You may use any model you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Test your model\n",
    "Test your model. If necessary change something and train your model again.\n",
    "Your goal is to prepare the model with the accuracy >= 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "116f0d98ee075869b5dc9f458adbcef3f5ec480ac835205e10bc39137d90951d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
