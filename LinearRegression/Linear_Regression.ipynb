{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Linear regression introduction</h1>\n",
    "<h2>\n",
    "Deep learning classes<br>\n",
    "</h2>\n",
    "<h3>\n",
    "This is a graded assignment<br>\n",
    "</h3>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic information\n",
    "<ul>\n",
    "    <li>This task is build of:\n",
    "    <ul>\n",
    "        <li>Descriptions (in the Markdown cells)\n",
    "        <li>Already prepared fragments of code\n",
    "        <li>The placeholders for your code\n",
    "    </ul>\n",
    "    <li>Your code should be entered in the `Code` cells. The places are marked by <b># ENTER YOUR CODE HERE</b> note.\n",
    "    <li>Usually you should enter only a few lines of code. But if you think you need it, you may use as many lines and add as many new code cells as you wish.\n",
    "    <li>You should solve the assignment in the defined order. It is often impossible to solve the next task, if you did not sove the previous one.\n",
    "    <li>This assignment is graded. \n",
    "    <li>During the grading you may expect some questions. <b>Sending the code to the teacher is not sufficient for passing.</b>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PrzemekSekula/DeepLearningClasses1/blob/master/LinearRegression/Linear_Regression.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all the necessary libraries, and set some initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/PrzemekSekula/DeepLearningClasses1/master/LinearRegression/helper_linear_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_linear_regression as hlp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is used for generating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below assures that the random function will return the same values every time\n",
    "np.random.seed(12)\n",
    "\n",
    "coefs = [50, 25, -1.25, 0.01]\n",
    "datalength = 80\n",
    "noise = 0.2\n",
    "\n",
    "x, y = hlp.getXY(coefs, datalength, noise)\n",
    "\n",
    "f = plt.figure()\n",
    "plt.scatter(x, y)\n",
    "plt.title('Your dataset')\n",
    "plt.xlabel('X (inputs)')\n",
    "plt.ylabel('Y (labels / targets)');\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Let's assume that your function is linear ($y = \\Theta_0 + \\Theta_1*x$). Try to select the $\\Theta_0$ i  $\\Theta_1$ manually in order to create your model. Use the code below for visualizing results.\n",
    "\n",
    "*Note: This task is not about machine learning. You should just select the parameters manually, in order to get a good intuition. The parateres should be \"quite good\", but they do not have to be perfect.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_th0 = 0 # ENTER YOUR CODE HERE (tune this parameter)\n",
    "my_th1 = 0 # ENTER YOUR CODE HERE (tune this parameter)\n",
    "\n",
    "hlp.plot_fitting_lin(x, y, my_th0, my_th1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2  - Hypothesis\n",
    "Prepare the function, which can compute the progosed values $h(x)$ according to the formula:\n",
    "\n",
    "<center>\n",
    "$h(x)  = \\Theta_0 + \\Theta_1 * x$\n",
    "</center>\n",
    "\n",
    "Function arguments:\n",
    "<li>x - input data (vector)\n",
    "<li>th0 - $\\Theta_0$\n",
    "<li>th1 - $\\Theta_1$\n",
    "<br \\>\n",
    "Function returns:\n",
    "<li>h - vector of values computed with the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_h(x, th0, th1):\n",
    "    x = np.asarray(x) # It removes problems with older version of libraries\n",
    "    \n",
    "    # ENTER YOUR CODE HERE\n",
    "\n",
    "    h = None\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    return h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 - test code\n",
    "You may use the code below, to test your output. The correct results are:<br>\n",
    "[200 185 170 155 140 125 110  95  80  65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.testcomputeh(compute_h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Cost function\n",
    "Prepare the function, which computes the cost, according to the formula:\n",
    "<br /><br />\n",
    "<center>\n",
    "$J = \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - h(x_i))}^2$\n",
    "</center>\n",
    "\n",
    "Where:\n",
    "\n",
    "<li>$J$ - cost\n",
    "<li>$y$ - real $y$ values\n",
    "<li>$y_{pred}$ - predicted $y$ values\n",
    "<li>$m$ - length of the $y$ vector (number of observations)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "<li>y - vector with real y values\n",
    "<li>h - vector with predicted y values ($h(x)$)\n",
    "\n",
    "Function returns:\n",
    "\n",
    "<li> c - cost computed with the given formula.\n",
    "    \n",
    "    \n",
    "*Note: You may compute the mean value of the vector by using: np.mean() function.\n",
    "Example:*\n",
    "<code>\n",
    "X = [1, 2, 3]\n",
    "print (np.mean(X))\n",
    "2\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y, ypred):\n",
    "    y = np.asarray(y) # It removes problems with older version of libraries\n",
    "    ypred = np.asarray(ypred) # It removes problems with older version of libraries\n",
    "    \n",
    "    #ENTER YOUR CODE HERE\n",
    "    \n",
    "    c = None\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    return c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 - test code\n",
    "You may test your `cost` function with the code below. If everything is OK, the output will be:<br>\n",
    "**Your code seems to be OK!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.testcost(cost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Computing cost\n",
    "Using the parameters $\\Theta_0$ i $\\Theta_1$ selected in the task 1 compute and display the hypothesis and the cost value.\n",
    "\n",
    "*Note 1: Your parameters are stored in `my_th0` and `my_th1` variables.*<br>\n",
    "*Note 1: You may use your `compute_h` function for computing hypothesis, and `cost` function for computing cost*<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = None # ENTER YOUR CODE HERE\n",
    "mycost = None  # ENTER YOUR CODE HERE\n",
    "print (mycost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - partial derivatives\n",
    "Prepare the function `compute_derivatives`, which returns the partial derivatives $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$ and $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$ where:\n",
    "<center>\n",
    "<br \\><br \\>\n",
    "$J(\\Theta_0, \\Theta_1) = \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))}^2= \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - (\\Theta_0 + \\Theta_1x_i))}^2$\n",
    "<br \\><br \\>\n",
    "$\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1) = - \\frac{1}{m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))}$\n",
    "<br \\><br \\>\n",
    "$\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1) = - \\frac{1}{m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))x_i}$\n",
    "<br \\><br \\>\n",
    "</center>\n",
    "\n",
    "Arguments:\n",
    "<li>x - input data vector\n",
    "<li>y - output data (labels) vector\n",
    "<li>th0 - $\\Theta_0$ parameter\n",
    "<li>th1 - $\\Theta_1$ parameter\n",
    "<br \\>\n",
    "\n",
    "Function returns:\n",
    "<li>dTh0 - partial derivative $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
    "<li>dTh1 - partial derivative $\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
    "<br \\><br \\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(x, y, th0, th1):\n",
    "    x = np.asarray(x) # It removes problems with older version of libraries\n",
    "    y = np.asarray(y) # It removes problems with older version of libraries\n",
    "    \n",
    "    # ENTER YOUR CODE HERE\n",
    "    \n",
    "    dTh0 = None\n",
    "    dTh1 = None\n",
    "    \n",
    "    #END OF YOUR CODE\n",
    "    return dTh0, dTh1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 - test code\n",
    "You may test your `compute_derivative` function with the code below. If everything is OK, the output will be:<br>\n",
    "**dTh0 seems to be OK.**<br>\n",
    "**dTh1 seems to be OK.**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.testcomputederivatives(compute_derivatives)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - updating theta\n",
    "Prepare the `update_theta` function, which updates the values of $\\Theta$ parameters according to the formulas:\n",
    "<center>\n",
    "<br \\><br \\>\n",
    "$\\Theta_0 = \\Theta_0 - \\alpha * \\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
    "<br \\><br \\>\n",
    "$\\Theta_1 = \\Theta_1 - \\alpha * \\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
    "<br \\><br \\>\n",
    "<br \\><br \\>\n",
    "</center>\n",
    "\n",
    "Arguments:\n",
    "<li>th0 - $\\Theta_0$ parameter\n",
    "<li>th1 - $\\Theta_1$ parameter\n",
    "<li>del0 - Partial derivative $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
    "<li>del1 - Partial derivative $\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
    "<li>learning_rate - the learning rate $\\alpha$ parameter\n",
    "<br \\><br \\>\n",
    "Function returns:\n",
    "<li>Updated value of $\\Theta_0$\n",
    "<li>Updated value of $\\Theta_1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta(th0, th1, del0, del1, learning_rate):\n",
    "\n",
    "    # ENTER YOUR CODE HERE\n",
    "    \n",
    "    th0 = None\n",
    "    th1 = None\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    return th0, th1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5 - test code\n",
    "You may test your `update_theta` function with the code below. If everything is OK, the output will be:<br>\n",
    "**theta0 seems to be OK.**<br>\n",
    "**theta1 seems to be OK.**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.testupdatetheta(update_theta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - learning parameters\n",
    "Tune the learning parameters and run the code below. This code will perform entire machine learning, using the functions you prepared in previous tasks.<br>\n",
    "The parameters are as follows:\n",
    "<ul>\n",
    "    <li>learning_rate - $\\alpha$ - learning coefficient. The greater $\\alpha$ the larger change of $\\Theta$ values in each iteration.\n",
    "    <li>epochs - how many times we should repeat the iterations\n",
    "</ul>\n",
    "<br \\>\n",
    "Additional parameter:\n",
    "<ul>\n",
    "<li>display_every - how often should we display the $\\Theta$ and cost values. This parameter does not play any role in learning process, it is only for observations. The value <code> display_every = int(epochs / 20) </code> is reasonable, but you may change it if you wish.\n",
    "</ul>\n",
    "    \n",
    "    \n",
    "*Note: The results for this part may differ because they depend on your parameters. To pass you need to push your cost below 15000. The optimal results are:*<br>\n",
    "<li>$\\Theta_0$ = 352.40171716\n",
    "<li>$\\Theta_1$ = -17.49921637\n",
    "<li>$J(\\Theta_0, \\Theta_1)$ = 14725.144411377056\n",
    "    \n",
    "**WARNING: It is difficult to get the optimal parameters with this algorithm. If your cost $J(\\Theta_0, \\Theta_1)$ is below 14800 it means that you are ok. If your cost is below 14730 you are perfect :)**\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1 # ENTER YOUR CODE HERE (Tune this parameter)\n",
    "epochs = 50 # ENTER YOUR CODE HERE (Tune this parameter)\n",
    "\n",
    "display_every = int(epochs / 20)\n",
    "\n",
    "th0 = 0 #The initial th0 value\n",
    "th1 = 0 #The initial th1 value\n",
    "\n",
    "cost_list = [] # we will use this list to plot the cost function chart\n",
    "iter_list = [] # we will use this list to plot the cost function chart\n",
    "\n",
    "for i in range(epochs):\n",
    "    #Learning process. With your functions the entire learning code is only 2 lines\n",
    "    del0, del1 = compute_derivatives(x, y, th0, th1)\n",
    "    th0, th1 = update_theta(th0, th1, del0, del1, learning_rate)\n",
    "    \n",
    "    #This code is used only for displaying results. You do not need to understand it\n",
    "    if ((i%display_every) == 0) | (i == epochs-1):\n",
    "        curr_cost = cost(y, compute_h(x, th0, th1))\n",
    "        cost_list.append(curr_cost)\n",
    "        iter_list.append(i)\n",
    "        print('Iteration {}, Theta 0: {:.2f}, Theta 1: {:.2f}, Cost: {:.2f}'\n",
    "              .format(i, th0, th1, curr_cost))\n",
    "\n",
    "        \n",
    "#This code is used only for displaying results. You do not need to understand it\n",
    "f = plt.figure()\n",
    "plt.plot(iter_list, cost_list)\n",
    "plt.title(\"Cost function\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may use the code below to present your results on the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nYour results:')\n",
    "print ('h(x) = {:.2f} + x*{:.2f}'.format(th0, th1))\n",
    "print('Cost = {:.2f}'.format(cost(y, compute_h(x, th0, th1))))\n",
    "\n",
    "hlp.plot_fitting_lin(x, y, th0, th1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Compare the 'manual' results with the 'gradient descent' results using the code below. Which results are better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The gradient descent results:')\n",
    "print ('h(x) = {:.2f} + x*{:.2f}'.format(th0, th1))\n",
    "print('Cost = {:.2f}'.format(cost(y, compute_h(x, th0, th1))))\n",
    "\n",
    "print('\\nThe manual results:')\n",
    "print ('h(x) = {:.2f} + x*{:.2f}'.format(my_th0, my_th1))\n",
    "print('Cost = {:.2f}'.format(cost(y, compute_h(x, my_th0, my_th1))))\n",
    "print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTER YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "116f0d98ee075869b5dc9f458adbcef3f5ec480ac835205e10bc39137d90951d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
